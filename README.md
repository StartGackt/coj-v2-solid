# Thai Legal NLP Analysis Service

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104.1-green.svg)](https://fastapi.tiangolo.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A comprehensive FastAPI-based application for Natural Language Processing (NLP) tasks on Thai legal documents. Built with SOLID principles for maintainability and scalability, featuring advanced AI models for legal text analysis, question answering, and semantic search.

## âœ¨ Features

- **ğŸ” Legal Document Analysis**: Extract obligations, exceptions, and compliance steps from Thai legal articles
- **ğŸ¤– NLP Pipeline**: Named Entity Recognition (NER), text classification, and semantic search
- **ğŸ“Š Knowledge Graph**: Neo4j-powered graph database for legal entity relationships
- **â“ Question Answering**: Fine-tuned models for legal Q&A based on context
- **ğŸ” Semantic Search**: Meaning-based document retrieval using sentence transformers
- **ğŸ—„ï¸ Database Integration**: PostgreSQL for structured data + Neo4j for knowledge graphs
- **ğŸ”„ Model Fine-tuning**: Scripts to improve AI models on legal domain data
- **ğŸ“ˆ Monitoring**: Health checks and logging for production deployment

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI       â”‚    â”‚   Services      â”‚    â”‚   Repositories  â”‚
â”‚   Endpoints     â”‚â—„â”€â”€â–ºâ”‚   Business      â”‚â—„â”€â”€â–ºâ”‚   Data Access   â”‚
â”‚                 â”‚    â”‚   Logic         â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PostgreSQL    â”‚    â”‚     Neo4j       â”‚    â”‚   AI Models     â”‚
â”‚   Structured    â”‚    â”‚   Knowledge     â”‚    â”‚   (Transformers)â”‚
â”‚   Data          â”‚    â”‚   Graph         â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ Prerequisites

- **Python**: 3.11 or higher
- **Databases**:
  - PostgreSQL 13+ (for structured data)
  - Neo4j 5.0+ (for knowledge graphs)
- **Package Manager**: uv (recommended) or pip
- **Memory**: 8GB+ RAM recommended for model training

## ğŸš€ Quick Start

### 1. Clone and Setup

```bash
git clone https://github.com/StartGackt/coj-v2-solid.git
cd coj-v2-solid
```

### 2. Environment Setup

```bash
# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
uv pip install -e .
```

### 3. Database Configuration

```bash
# Copy environment template
cp .env.example .env

# Edit .env with your database credentials
nano .env
```

**Required Environment Variables:**

```env
# PostgreSQL
DATABASE_URL=postgresql://user:password@localhost:5432/legal_nlp

# Neo4j
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password

# Optional: OpenAI API for enhanced features
OPENAI_API_KEY=your_key_here
```

### 4. Database Initialization

```bash
# Run PostgreSQL migrations
alembic upgrade head

# Ensure Neo4j is running and accessible
```

### 5. Start the Application

```bash
python main.py
```

Visit `http://127.0.0.1:8000/docs` for interactive API documentation.

## ğŸ“– Usage

### API Endpoints

#### Legal Article Analysis

```bash
curl -X POST "http://localhost:8000/api/v1/legal-ontology/analyze" \
  -H "Content-Type: application/json" \
  -d '{
    "article_number": "à¸¡à¸²à¸•à¸£à¸² 12",
    "summary": "à¸«à¹‰à¸²à¸¡à¸™à¸²à¸¢à¸ˆà¹‰à¸²à¸‡à¹€à¸£à¸µà¸¢à¸à¸«à¸¥à¸±à¸à¸›à¸£à¸°à¸à¸±à¸™à¸ˆà¸²à¸à¸¥à¸¹à¸à¸ˆà¹‰à¸²à¸‡ à¸¢à¸à¹€à¸§à¹‰à¸™à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸£à¸±à¸šà¸œà¸´à¸”à¸Šà¸­à¸šà¸”à¹‰à¸²à¸™à¸à¸²à¸£à¹€à¸‡à¸´à¸™",
    "obligations": [
      {
        "actor": "à¸™à¸²à¸¢à¸ˆà¹‰à¸²à¸‡",
        "action": "à¸•à¹‰à¸­à¸‡à¹„à¸¡à¹ˆà¹€à¸£à¸µà¸¢à¸à¸«à¸£à¸·à¸­à¸£à¸±à¸šà¸«à¸¥à¸±à¸à¸›à¸£à¸°à¸à¸±à¸™à¸ˆà¸²à¸à¸¥à¸¹à¸à¸ˆà¹‰à¸²à¸‡",
        "timeline": null
      }
    ],
    "exceptions": [
      {
        "description": "à¸­à¸™à¸¸à¸à¸²à¸•à¹ƒà¸«à¹‰à¹€à¸£à¸µà¸¢à¸à¸«à¸¥à¸±à¸à¸›à¸£à¸°à¸à¸±à¸™à¹€à¸¡à¸·à¹ˆà¸­à¸«à¸™à¹‰à¸²à¸—à¸µà¹ˆà¸¥à¸¹à¸à¸ˆà¹‰à¸²à¸‡à¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡à¸à¸±à¸šà¸à¸²à¸£à¹€à¸‡à¸´à¸™"
      }
    ]
  }'
```

#### Question Answering

```bash
curl -X POST "http://localhost:8000/api/v1/qa/ask" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "à¸«à¹‰à¸²à¸¡à¸™à¸²à¸¢à¸ˆà¹‰à¸²à¸‡à¹€à¸£à¸µà¸¢à¸à¸«à¸¥à¸±à¸à¸›à¸£à¸°à¸à¸±à¸™à¸ˆà¸²à¸à¹ƒà¸„à¸£",
    "context": "à¸¡à¸²à¸•à¸£à¸² 12 à¸«à¹‰à¸²à¸¡à¸¡à¸´à¹ƒà¸«à¹‰à¸™à¸²à¸¢à¸ˆà¹‰à¸²à¸‡à¹€à¸£à¸µà¸¢à¸à¸«à¸£à¸·à¸­à¸£à¸±à¸šà¸«à¸¥à¸±à¸à¸›à¸£à¸°à¸à¸±à¸™à¹€à¸à¸·à¹ˆà¸­à¸à¸²à¸£à¹ƒà¸”à¹† à¸ˆà¸²à¸à¸¥à¸¹à¸à¸ˆà¹‰à¸²à¸‡"
  }'
```

#### Semantic Search

```bash
curl -X POST "http://localhost:8000/api/v1/search/semantic" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "à¸à¸à¸«à¸¡à¸²à¸¢à¹à¸£à¸‡à¸‡à¸²à¸™",
    "limit": 10
  }'
```

### Training Scripts

#### Train Text Classifier

```bash
python scripts/train_text_classifier.py
```

#### Fine-tune QA Model

```bash
python scripts/finetune_qa_model.py
```

#### Fine-tune Semantic Search

```bash
python scripts/finetune_semantic_search.py
```

This script now consumes curated triplets from `app/dataset/semantic_triplets.json`. Each entry defines an anchor query, the most relevant legal article (`positive`), and optional `hard_negatives` that the model should learn to distinguish. You can expand the dataset by appending new triplets that reference articles available in `app/dataset/data1.txt`. During fine-tuning the script augments each triplet with extra random negatives to produce a rich training set.

## ğŸ§ª Testing

```bash
# Run all tests
uv run pytest

# Run with coverage
uv run pytest --cov=app --cov-report=html

# Run specific test file
uv run pytest tests/test_legal_article_analysis.py -v
```

## ğŸ”§ Development

### Project Structure

```
coj-v2-solid/
â”œâ”€â”€ alembic/              # Database migrations
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/             # FastAPI route handlers
â”‚   â”œâ”€â”€ core/            # Configuration & settings
â”‚   â”œâ”€â”€ db/              # Database models & connections
â”‚   â”œâ”€â”€ models/          # Pydantic schemas
â”‚   â”œâ”€â”€ nlp/             # NLP processing modules
â”‚   â”œâ”€â”€ repositories/    # Data access layer
â”‚   â””â”€â”€ services/        # Business logic
â”œâ”€â”€ models/              # Trained AI models
â”œâ”€â”€ scripts/             # Training & utility scripts
â”œâ”€â”€ tests/               # Test suite
â””â”€â”€ main.py              # Application entry point
```

### Adding New Features

1. **API Endpoints**: Add routes in `app/api/v1/endpoints/`
2. **Business Logic**: Implement services in `app/services/`
3. **Data Models**: Define schemas in `app/models/`
4. **Database Changes**: Create migrations with `alembic revision`

### Code Quality

```bash
# Format code
uv run black .

# Lint code
uv run flake8 .

# Type checking
uv run mypy .
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Development Guidelines

- Follow SOLID principles
- Write tests for new features
- Update documentation
- Use type hints
- Keep commits atomic and descriptive

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Built with [FastAPI](https://fastapi.tiangolo.com/) and [Neo4j](https://neo4j.com/)
- NLP powered by [Hugging Face Transformers](https://huggingface.co/)
- Inspired by Thai legal document processing challenges

## ğŸ“ Support

For questions or issues:

- Open an [issue](https://github.com/StartGackt/coj-v2-solid/issues) on GitHub
- Check the [documentation](https://github.com/StartGackt/coj-v2-solid/wiki)

---

**Note**: This project is designed for Thai legal text processing. For other languages, model fine-tuning may be required.
